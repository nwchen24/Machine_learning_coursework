{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipelines\n",
    "\n",
    "In this exercise, you will practice pasting together multiple feature processing steps into a single pipeline that allows for easy cross-validation and model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the crime rate data that we have used in previous weeks. This time, we will not drop the first few columns or the rows with missing values in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load some crime data\n",
    "headers = pd.read_csv('comm_names.txt', squeeze=True)\n",
    "headers = headers.apply(lambda s: s.split()[1])\n",
    "crime = (pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', \n",
    "                    header=None, na_values=['?'], names=headers)\n",
    "#          .iloc[:, 5:]\n",
    "#          .dropna()\n",
    "         )\n",
    "\n",
    "# Set target and predictors\n",
    "target = 'ViolentCrimesPerPop'\n",
    "predictors = [c for c in crime.columns if not c == target]\n",
    "\n",
    "# Train/test split\n",
    "X = crime[predictors]\n",
    "y = crime[[target]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "# train_df, test_df = train_test_split(crime, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always start by taking a look at the first few rows of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>...</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>79.0</td>\n",
       "      <td>17975.0</td>\n",
       "      <td>Cudahycity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gallupcity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petalumacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waycrosscity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Templecity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    county  community communityname  fold  population  householdsize  \\\n",
       "55    79.0    17975.0    Cudahycity    10        0.01           0.36   \n",
       "35     NaN        NaN    Gallupcity     8        0.01           0.67   \n",
       "6      NaN        NaN  Petalumacity     1        0.05           0.46   \n",
       "13     NaN        NaN  Waycrosscity     8        0.01           0.36   \n",
       "48     NaN        NaN    Templecity     8        0.06           0.38   \n",
       "\n",
       "    racepctblack  racePctWhite  racePctAsian  racePctHisp       ...         \\\n",
       "55          0.01          0.97          0.04         0.04       ...          \n",
       "35          0.02          0.23          0.07         0.64       ...          \n",
       "6           0.02          0.88          0.20         0.17       ...          \n",
       "13          0.95          0.24          0.03         0.01       ...          \n",
       "48          0.33          0.59          0.05         0.25       ...          \n",
       "\n",
       "    PolicAveOTWorked  LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "55               NaN      0.01     0.33            0.26        NaN   \n",
       "35               NaN      0.03     0.14            0.01        NaN   \n",
       "6                NaN      0.03     0.29            0.24        NaN   \n",
       "13               NaN      0.03     0.12            0.01        NaN   \n",
       "48               NaN      0.12     0.09            0.01        NaN   \n",
       "\n",
       "    PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "55            NaN                  NaN                  NaN   \n",
       "35            NaN                  NaN                  NaN   \n",
       "6             NaN                  NaN                  NaN   \n",
       "13            NaN                  NaN                  NaN   \n",
       "48            NaN                  NaN                  NaN   \n",
       "\n",
       "    LemasPctOfficDrugUn  PolicBudgPerPop  \n",
       "55                  0.0              NaN  \n",
       "35                  0.0              NaN  \n",
       "6                   0.0              NaN  \n",
       "13                  0.0              NaN  \n",
       "48                  0.0              NaN  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "It's always a good idea to start by asking yourself a few questions about the data. For example\n",
    "- What types of features are there?\n",
    "- Are there missing values?\n",
    "- What is the distribution of the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What types of features are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    124\n",
       "int64        1\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county                  float64\n",
       "community               float64\n",
       "communityname            object\n",
       "fold                      int64\n",
       "population              float64\n",
       "householdsize           float64\n",
       "racepctblack            float64\n",
       "racePctWhite            float64\n",
       "racePctAsian            float64\n",
       "racePctHisp             float64\n",
       "agePct12t21             float64\n",
       "agePct12t29             float64\n",
       "agePct16t24             float64\n",
       "agePct65up              float64\n",
       "numbUrban               float64\n",
       "pctUrban                float64\n",
       "medIncome               float64\n",
       "pctWWage                float64\n",
       "pctWFarmSelf            float64\n",
       "pctWInvInc              float64\n",
       "pctWSocSec              float64\n",
       "pctWPubAsst             float64\n",
       "pctWRetire              float64\n",
       "medFamInc               float64\n",
       "perCapInc               float64\n",
       "whitePerCap             float64\n",
       "blackPerCap             float64\n",
       "indianPerCap            float64\n",
       "AsianPerCap             float64\n",
       "OtherPerCap             float64\n",
       "                         ...   \n",
       "PctBornSameState        float64\n",
       "PctSameHouse85          float64\n",
       "PctSameCity85           float64\n",
       "PctSameState85          float64\n",
       "LemasSwornFT            float64\n",
       "LemasSwFTPerPop         float64\n",
       "LemasSwFTFieldOps       float64\n",
       "LemasSwFTFieldPerPop    float64\n",
       "LemasTotalReq           float64\n",
       "LemasTotReqPerPop       float64\n",
       "PolicReqPerOffic        float64\n",
       "PolicPerPop             float64\n",
       "RacialMatchCommPol      float64\n",
       "PctPolicWhite           float64\n",
       "PctPolicBlack           float64\n",
       "PctPolicHisp            float64\n",
       "PctPolicAsian           float64\n",
       "PctPolicMinor           float64\n",
       "OfficAssgnDrugUnits     float64\n",
       "NumKindsDrugsSeiz       float64\n",
       "PolicAveOTWorked        float64\n",
       "LandArea                float64\n",
       "PopDens                 float64\n",
       "PctUsePubTrans          float64\n",
       "PolicCars               float64\n",
       "PolicOperBudg           float64\n",
       "LemasPctPolicOnPatr     float64\n",
       "LemasGangUnitDeploy     float64\n",
       "LemasPctOfficDrugUn     float64\n",
       "PolicBudgPerPop         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county                   890\n",
       "community                893\n",
       "communityname              0\n",
       "fold                       0\n",
       "population                 0\n",
       "householdsize              0\n",
       "racepctblack               0\n",
       "racePctWhite               0\n",
       "racePctAsian               0\n",
       "racePctHisp                0\n",
       "agePct12t21                0\n",
       "agePct12t29                0\n",
       "agePct16t24                0\n",
       "agePct65up                 0\n",
       "numbUrban                  0\n",
       "pctUrban                   0\n",
       "medIncome                  0\n",
       "pctWWage                   0\n",
       "pctWFarmSelf               0\n",
       "pctWInvInc                 0\n",
       "pctWSocSec                 0\n",
       "pctWPubAsst                0\n",
       "pctWRetire                 0\n",
       "medFamInc                  0\n",
       "perCapInc                  0\n",
       "whitePerCap                0\n",
       "blackPerCap                0\n",
       "indianPerCap               0\n",
       "AsianPerCap                0\n",
       "OtherPerCap                1\n",
       "                        ... \n",
       "PctBornSameState           0\n",
       "PctSameHouse85             0\n",
       "PctSameCity85              0\n",
       "PctSameState85             0\n",
       "LemasSwornFT            1253\n",
       "LemasSwFTPerPop         1253\n",
       "LemasSwFTFieldOps       1253\n",
       "LemasSwFTFieldPerPop    1253\n",
       "LemasTotalReq           1253\n",
       "LemasTotReqPerPop       1253\n",
       "PolicReqPerOffic        1253\n",
       "PolicPerPop             1253\n",
       "RacialMatchCommPol      1253\n",
       "PctPolicWhite           1253\n",
       "PctPolicBlack           1253\n",
       "PctPolicHisp            1253\n",
       "PctPolicAsian           1253\n",
       "PctPolicMinor           1253\n",
       "OfficAssgnDrugUnits     1253\n",
       "NumKindsDrugsSeiz       1253\n",
       "PolicAveOTWorked        1253\n",
       "LandArea                   0\n",
       "PopDens                    0\n",
       "PctUsePubTrans             0\n",
       "PolicCars               1253\n",
       "PolicOperBudg           1253\n",
       "LemasPctPolicOnPatr     1253\n",
       "LemasGangUnitDeploy     1253\n",
       "LemasPctOfficDrugUn        0\n",
       "PolicBudgPerPop         1253\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.apply(lambda col: col.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the distribution of the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x116d4f910>]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d33890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the distributions of the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are both continuous and categorical features. It is usually a good idea to separate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_predictors = X_train.columns[4:]\n",
    "categorical_predictors = ['county', 'community', 'fold', 'communityname']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.122571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.165073</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.177331</td>\n",
       "      <td>0.252775</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.752020</td>\n",
       "      <td>0.246175</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.153860</td>\n",
       "      <td>0.211290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctHisp</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.150843</td>\n",
       "      <td>0.239894</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t21</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.423157</td>\n",
       "      <td>0.153432</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t29</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.493331</td>\n",
       "      <td>0.142199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct16t24</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.335097</td>\n",
       "      <td>0.163870</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct65up</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.423880</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbUrban</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.063438</td>\n",
       "      <td>0.124029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctUrban</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.700508</td>\n",
       "      <td>0.442880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medIncome</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.360676</td>\n",
       "      <td>0.207475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWWage</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.557719</td>\n",
       "      <td>0.182848</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.294040</td>\n",
       "      <td>0.207067</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWInvInc</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.495585</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWSocSec</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.471625</td>\n",
       "      <td>0.173880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.318207</td>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWRetire</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.480823</td>\n",
       "      <td>0.168086</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medFamInc</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.375030</td>\n",
       "      <td>0.196597</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perCapInc</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.349244</td>\n",
       "      <td>0.189196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitePerCap</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.367338</td>\n",
       "      <td>0.185614</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackPerCap</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.293204</td>\n",
       "      <td>0.175106</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indianPerCap</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.201251</td>\n",
       "      <td>0.161950</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AsianPerCap</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.320381</td>\n",
       "      <td>0.195006</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherPerCap</th>\n",
       "      <td>1494.0</td>\n",
       "      <td>0.284485</td>\n",
       "      <td>0.188322</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HispPerCap</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.385666</td>\n",
       "      <td>0.180306</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumUnderPov</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.055231</td>\n",
       "      <td>0.126146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.304167</td>\n",
       "      <td>0.230261</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.318201</td>\n",
       "      <td>0.215811</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctBornSameState</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.609391</td>\n",
       "      <td>0.203908</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.535967</td>\n",
       "      <td>0.179911</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameCity85</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.628221</td>\n",
       "      <td>0.199217</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameState85</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.655538</td>\n",
       "      <td>0.194837</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwornFT</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.066529</td>\n",
       "      <td>0.135247</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwFTPerPop</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.217273</td>\n",
       "      <td>0.158096</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwFTFieldOps</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.129899</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwFTFieldPerPop</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.246860</td>\n",
       "      <td>0.155686</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasTotalReq</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.093223</td>\n",
       "      <td>0.157376</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasTotReqPerPop</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.211694</td>\n",
       "      <td>0.168978</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicReqPerOffic</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.338802</td>\n",
       "      <td>0.198911</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicPerPop</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.217314</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RacialMatchCommPol</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.689132</td>\n",
       "      <td>0.229404</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicWhite</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.717851</td>\n",
       "      <td>0.231725</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicBlack</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.226653</td>\n",
       "      <td>0.244265</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicHisp</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.141116</td>\n",
       "      <td>0.205428</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.1775</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicAsian</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.119711</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicMinor</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.269215</td>\n",
       "      <td>0.238202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OfficAssgnDrugUnits</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.073802</td>\n",
       "      <td>0.117941</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumKindsDrugsSeiz</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.562893</td>\n",
       "      <td>0.203204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.307893</td>\n",
       "      <td>0.232727</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandArea</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.063766</td>\n",
       "      <td>0.103681</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PopDens</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.234067</td>\n",
       "      <td>0.204418</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.163853</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicCars</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.156116</td>\n",
       "      <td>0.208316</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.137365</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.707686</td>\n",
       "      <td>0.211007</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.448347</td>\n",
       "      <td>0.412986</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>0.095244</td>\n",
       "      <td>0.239836</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.192603</td>\n",
       "      <td>0.162195</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count      mean       std   min     25%    50%     75%  \\\n",
       "population            1495.0  0.056883  0.122571  0.00  0.0100  0.020  0.0600   \n",
       "householdsize         1495.0  0.464074  0.165073  0.00  0.3500  0.440  0.5400   \n",
       "racepctblack          1495.0  0.177331  0.252775  0.00  0.0200  0.060  0.2200   \n",
       "racePctWhite          1495.0  0.752020  0.246175  0.00  0.6300  0.840  0.9400   \n",
       "racePctAsian          1495.0  0.153860  0.211290  0.00  0.0400  0.070  0.1600   \n",
       "racePctHisp           1495.0  0.150843  0.239894  0.00  0.0150  0.040  0.1650   \n",
       "agePct12t21           1495.0  0.423157  0.153432  0.00  0.3300  0.400  0.4800   \n",
       "agePct12t29           1495.0  0.493331  0.142199  0.00  0.4100  0.480  0.5400   \n",
       "agePct16t24           1495.0  0.335097  0.163870  0.00  0.2500  0.290  0.3600   \n",
       "agePct65up            1495.0  0.423880  0.179779  0.00  0.3000  0.420  0.5300   \n",
       "numbUrban             1495.0  0.063438  0.124029  0.00  0.0000  0.030  0.0700   \n",
       "pctUrban              1495.0  0.700508  0.442880  0.00  0.0000  1.000  1.0000   \n",
       "medIncome             1495.0  0.360676  0.207475  0.00  0.2000  0.320  0.4900   \n",
       "pctWWage              1495.0  0.557719  0.182848  0.00  0.4500  0.570  0.6900   \n",
       "pctWFarmSelf          1495.0  0.294040  0.207067  0.00  0.1500  0.230  0.3700   \n",
       "pctWInvInc            1495.0  0.495585  0.179209  0.00  0.3650  0.480  0.6200   \n",
       "pctWSocSec            1495.0  0.471625  0.173880  0.00  0.3500  0.480  0.5800   \n",
       "pctWPubAsst           1495.0  0.318207  0.223364  0.01  0.1400  0.260  0.4400   \n",
       "pctWRetire            1495.0  0.480823  0.168086  0.00  0.3600  0.470  0.5900   \n",
       "medFamInc             1495.0  0.375030  0.196597  0.00  0.2300  0.330  0.4800   \n",
       "perCapInc             1495.0  0.349244  0.189196  0.00  0.2200  0.300  0.4300   \n",
       "whitePerCap           1495.0  0.367338  0.185614  0.00  0.2400  0.320  0.4400   \n",
       "blackPerCap           1495.0  0.293204  0.175106  0.00  0.1800  0.250  0.3800   \n",
       "indianPerCap          1495.0  0.201251  0.161950  0.00  0.1100  0.170  0.2500   \n",
       "AsianPerCap           1495.0  0.320381  0.195006  0.00  0.1900  0.280  0.4000   \n",
       "OtherPerCap           1494.0  0.284485  0.188322  0.00  0.1700  0.260  0.3600   \n",
       "HispPerCap            1495.0  0.385666  0.180306  0.00  0.2600  0.340  0.4800   \n",
       "NumUnderPov           1495.0  0.055231  0.126146  0.00  0.0100  0.020  0.0500   \n",
       "PctPopUnderPov        1495.0  0.304167  0.230261  0.00  0.1100  0.240  0.4500   \n",
       "PctLess9thGrade       1495.0  0.318201  0.215811  0.00  0.1600  0.270  0.4200   \n",
       "...                      ...       ...       ...   ...     ...    ...     ...   \n",
       "PctBornSameState      1495.0  0.609391  0.203908  0.00  0.4700  0.630  0.7700   \n",
       "PctSameHouse85        1495.0  0.535967  0.179911  0.00  0.4250  0.540  0.6600   \n",
       "PctSameCity85         1495.0  0.628221  0.199217  0.00  0.5200  0.670  0.7700   \n",
       "PctSameState85        1495.0  0.655538  0.194837  0.00  0.5600  0.710  0.7900   \n",
       "LemasSwornFT           242.0  0.066529  0.135247  0.00  0.0100  0.020  0.0500   \n",
       "LemasSwFTPerPop        242.0  0.217273  0.158096  0.00  0.1300  0.180  0.2500   \n",
       "LemasSwFTFieldOps      242.0  0.927273  0.129899  0.00  0.9400  0.970  0.9800   \n",
       "LemasSwFTFieldPerPop   242.0  0.246860  0.155686  0.00  0.1600  0.210  0.2875   \n",
       "LemasTotalReq          242.0  0.093223  0.157376  0.00  0.0200  0.040  0.0800   \n",
       "LemasTotReqPerPop      242.0  0.211694  0.168978  0.00  0.1200  0.170  0.2375   \n",
       "PolicReqPerOffic       242.0  0.338802  0.198911  0.00  0.2200  0.280  0.4300   \n",
       "PolicPerPop            242.0  0.217314  0.158113  0.00  0.1300  0.180  0.2500   \n",
       "RacialMatchCommPol     242.0  0.689132  0.229404  0.00  0.5525  0.750  0.8600   \n",
       "PctPolicWhite          242.0  0.717851  0.231725  0.00  0.6100  0.770  0.8900   \n",
       "PctPolicBlack          242.0  0.226653  0.244265  0.00  0.0500  0.130  0.3550   \n",
       "PctPolicHisp           242.0  0.141116  0.205428  0.00  0.0100  0.055  0.1775   \n",
       "PctPolicAsian          242.0  0.119711  0.230259  0.00  0.0000  0.000  0.1300   \n",
       "PctPolicMinor          242.0  0.269215  0.238202  0.00  0.0800  0.210  0.3575   \n",
       "OfficAssgnDrugUnits    242.0  0.073802  0.117941  0.00  0.0200  0.040  0.0800   \n",
       "NumKindsDrugsSeiz      242.0  0.562893  0.203204  0.00  0.4300  0.570  0.7100   \n",
       "PolicAveOTWorked       242.0  0.307893  0.232727  0.00  0.1400  0.250  0.4175   \n",
       "LandArea              1495.0  0.063766  0.103681  0.00  0.0200  0.040  0.0700   \n",
       "PopDens               1495.0  0.234067  0.204418  0.00  0.1000  0.170  0.2800   \n",
       "PctUsePubTrans        1495.0  0.163853  0.231840  0.00  0.0200  0.070  0.1900   \n",
       "PolicCars              242.0  0.156116  0.208316  0.00  0.0400  0.070  0.1800   \n",
       "PolicOperBudg          242.0  0.072975  0.137365  0.00  0.0200  0.030  0.0600   \n",
       "LemasPctPolicOnPatr    242.0  0.707686  0.211007  0.00  0.6300  0.760  0.8475   \n",
       "LemasGangUnitDeploy    242.0  0.448347  0.412986  0.00  0.0000  0.500  1.0000   \n",
       "LemasPctOfficDrugUn   1495.0  0.095244  0.239836  0.00  0.0000  0.000  0.0000   \n",
       "PolicBudgPerPop        242.0  0.192603  0.162195  0.00  0.1100  0.150  0.2200   \n",
       "\n",
       "                      max  \n",
       "population            1.0  \n",
       "householdsize         1.0  \n",
       "racepctblack          1.0  \n",
       "racePctWhite          1.0  \n",
       "racePctAsian          1.0  \n",
       "racePctHisp           1.0  \n",
       "agePct12t21           1.0  \n",
       "agePct12t29           1.0  \n",
       "agePct16t24           1.0  \n",
       "agePct65up            1.0  \n",
       "numbUrban             1.0  \n",
       "pctUrban              1.0  \n",
       "medIncome             1.0  \n",
       "pctWWage              1.0  \n",
       "pctWFarmSelf          1.0  \n",
       "pctWInvInc            1.0  \n",
       "pctWSocSec            1.0  \n",
       "pctWPubAsst           1.0  \n",
       "pctWRetire            1.0  \n",
       "medFamInc             1.0  \n",
       "perCapInc             1.0  \n",
       "whitePerCap           1.0  \n",
       "blackPerCap           1.0  \n",
       "indianPerCap          1.0  \n",
       "AsianPerCap           1.0  \n",
       "OtherPerCap           1.0  \n",
       "HispPerCap            1.0  \n",
       "NumUnderPov           1.0  \n",
       "PctPopUnderPov        1.0  \n",
       "PctLess9thGrade       1.0  \n",
       "...                   ...  \n",
       "PctBornSameState      1.0  \n",
       "PctSameHouse85        1.0  \n",
       "PctSameCity85         1.0  \n",
       "PctSameState85        1.0  \n",
       "LemasSwornFT          1.0  \n",
       "LemasSwFTPerPop       1.0  \n",
       "LemasSwFTFieldOps     1.0  \n",
       "LemasSwFTFieldPerPop  1.0  \n",
       "LemasTotalReq         1.0  \n",
       "LemasTotReqPerPop     1.0  \n",
       "PolicReqPerOffic      1.0  \n",
       "PolicPerPop           1.0  \n",
       "RacialMatchCommPol    1.0  \n",
       "PctPolicWhite         1.0  \n",
       "PctPolicBlack         1.0  \n",
       "PctPolicHisp          1.0  \n",
       "PctPolicAsian         1.0  \n",
       "PctPolicMinor         1.0  \n",
       "OfficAssgnDrugUnits   1.0  \n",
       "NumKindsDrugsSeiz     1.0  \n",
       "PolicAveOTWorked      1.0  \n",
       "LandArea              1.0  \n",
       "PopDens               1.0  \n",
       "PctUsePubTrans        1.0  \n",
       "PolicCars             1.0  \n",
       "PolicOperBudg         1.0  \n",
       "LemasPctPolicOnPatr   1.0  \n",
       "LemasGangUnitDeploy   1.0  \n",
       "LemasPctOfficDrugUn   1.0  \n",
       "PolicBudgPerPop       1.0  \n",
       "\n",
       "[122 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numeric_predictors].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "county\n",
      "3.0     58\n",
      "17.0    48\n",
      "9.0     34\n",
      "1.0     31\n",
      "7.0     28\n",
      "Name: county, dtype: int64\n",
      "community\n",
      "21344.0    2\n",
      "60120.0    2\n",
      "57000.0    2\n",
      "2060.0     2\n",
      "51000.0    2\n",
      "Name: community, dtype: int64\n",
      "fold\n",
      "6     155\n",
      "4     155\n",
      "5     154\n",
      "1     153\n",
      "10    152\n",
      "Name: fold, dtype: int64\n",
      "communityname\n",
      "Jacksonvillecity    5\n",
      "Greenvillecity      4\n",
      "Athenscity          4\n",
      "Columbuscity        3\n",
      "Milfordtown         3\n",
      "Name: communityname, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_predictors:\n",
    "    print col\n",
    "    print X_train[col].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `community` and `communityname` look like they are sliced too thin to be useful. `fold` is probably an index that was added for k-fold cross-validation. So it looks like the only real categorical variable is `county`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_predictors = ['county']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few obvious things we would like to do with this data before we start trying different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Impute missing values. For categorical variables, this is easy, a good strategy is to just add a new level: '?'. For the continuous variables, we need to be a little bit more careful.\n",
    "- All of our sklearn learning algorithms only work with numeric data. We need to convert the categorical column to numeric, using either one-hot encoding or feature hashing.\n",
    "- Some learning algorithms are sensitive to scaling. We should try normalizing the numeric features.\n",
    "- This dataset has a relatively large number of features, compared to a small number of examples. We might want to try some dimensionality reduction (will be discussed in future classes).\n",
    "\n",
    "There are different strategies for the two feature types (numeric and categorical), so we will treat them individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county\n",
       "55    79.0\n",
       "35     NaN\n",
       "6      NaN\n",
       "13     NaN\n",
       "48     NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[categorical_predictors].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though county is being represented with floating point numbers, we don't want the learning algorithm to treat it that way, so we should explicitly change it to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change to strings\n",
    "for col in categorical_predictors:\n",
    "    X_train.loc[:, col] = X_train[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan      890\n",
       "3.0       58\n",
       "17.0      48\n",
       "9.0       34\n",
       "1.0       31\n",
       "7.0       28\n",
       "27.0      26\n",
       "5.0       24\n",
       "21.0      24\n",
       "13.0      22\n",
       "23.0      22\n",
       "11.0      19\n",
       "25.0      18\n",
       "29.0      17\n",
       "35.0      15\n",
       "39.0      15\n",
       "31.0      11\n",
       "133.0     10\n",
       "71.0      10\n",
       "79.0       9\n",
       "15.0       8\n",
       "119.0      6\n",
       "45.0       6\n",
       "61.0       6\n",
       "101.0      6\n",
       "49.0       6\n",
       "93.0       5\n",
       "91.0       5\n",
       "77.0       5\n",
       "19.0       5\n",
       "        ... \n",
       "710.0      1\n",
       "67.0       1\n",
       "135.0      1\n",
       "215.0      1\n",
       "590.0      1\n",
       "660.0      1\n",
       "800.0      1\n",
       "99.0       1\n",
       "107.0      1\n",
       "193.0      1\n",
       "109.0      1\n",
       "73.0       1\n",
       "735.0      1\n",
       "181.0      1\n",
       "147.0      1\n",
       "57.0       1\n",
       "770.0      1\n",
       "127.0      1\n",
       "750.0      1\n",
       "670.0      1\n",
       "165.0      1\n",
       "690.0      1\n",
       "730.0      1\n",
       "173.0      1\n",
       "169.0      1\n",
       "131.0      1\n",
       "103.0      1\n",
       "830.0      1\n",
       "760.0      1\n",
       "775.0      1\n",
       "Name: county, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.county.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually fixes the second problem as well. The NaN (not a number) entries have just been changed to the string 'nan', which should be treated the same as any other category level.\n",
    "\n",
    "Now, the approach above is fine, but sklearn encourages us to treat feature processing and engineering in a very principled way. Feature processing steps in sklearn always have a .fit() method and a .transform() method, which has several advantages:\n",
    "1. It is easy to combine and/or chain together multiple processing steps.\n",
    "2. It helps keep the training and testing data separate, since .fit() only deals with training data and .transform() deals with both training and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we could write the feature processing step above 'the sklearn way':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_df = X\n",
    "        for col in self.cols:\n",
    "            transformed_df.loc[:, col] = transformed_df.loc[:, col].astype(str)\n",
    "        return transformed_df\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ci = CategoricalImputer(categorical_predictors)\n",
    "transformed_train = ci.fit_transform(X_train)\n",
    "transformed_test = ci.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical --> Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider two different ways of transforming categorical features to numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Feature Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "fh = FeatureHasher(n_features=5)\n",
    "feature_dict = X_train[categorical_predictors].to_dict(orient='records')\n",
    "fh.fit(feature_dict)\n",
    "out = pd.DataFrame(fh.transform(feature_dict).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "feature_dict = X_train[categorical_predictors].to_dict(orient='records')\n",
    "dv.fit(feature_dict)\n",
    "out = pd.DataFrame(\n",
    "    dv.transform(feature_dict),\n",
    "    columns = dv.feature_names_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Examine all of the objects in the above two code cells and make sure you understand what is happening. Next, write a class MyVectorizer. The goal is to write a single transformation step that can perform either one-hot encoding or feature hashing, depending on the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher, DictVectorizer\n",
    "\n",
    "class MyVectorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Vectorize a set of categorical variables\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cols, hashing=None):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            cols: a list of column names of the categorical variables\n",
    "            hashing: \n",
    "                If None, then vectorization is a simple one-hot-encoding.\n",
    "                If an integer, then hashing is the number of features in the output.\n",
    "        \"\"\"\n",
    "        self.cols = cols\n",
    "        self.hashing = hashing\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        data = X[self.cols]\n",
    "        \n",
    "        # Choose a vectorizer\n",
    "        if self.hashing is None:\n",
    "            self.myvec = DictVectorizer(sparse=False)\n",
    "        else:\n",
    "            self.myvec = FeatureHasher(n_features = self.hashing)\n",
    "    \n",
    "        self.myvec.fit(X[self.cols].to_dict(orient='records'))\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "            \n",
    "        # Vectorize Input\n",
    "        if self.hashing is None:\n",
    "            return pd.DataFrame(\n",
    "                self.myvec.transform(X[self.cols].to_dict(orient='records')),\n",
    "                columns = self.myvec.feature_names_\n",
    "            )\n",
    "        else:\n",
    "            return pd.DataFrame(\n",
    "                self.myvec.transform(X[self.cols].to_dict(orient='records')).toarray()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mv = MyVectorizer(cols=categorical_predictors, hashing=None)\n",
    "transformed_train = mv.fit_transform(X_train)\n",
    "transformed_test = mv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = MyVectorizer(cols=categorical_predictors, hashing=5)\n",
    "transformed_train = mv.fit_transform(X_train)\n",
    "transformed_test = mv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the continuous features, there are two main feature processing steps:\n",
    "1. Impute missing values\n",
    "2. Scale features to normalized z-scores.\n",
    "\n",
    "One can imagine other feature processing steps, e.g. dealing with outliers, discretization, etc., but we will stick with these for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write your own class, MyImputer that takes as an argument the columns you would like to impute missing values for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "class MyImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.imp = Imputer(strategy='mean')\n",
    "        self.imp.fit(X[self.cols])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.imp.transform(X[self.cols])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp = MyImputer(numeric_predictors)\n",
    "transformed_train = imp.fit_transform(X_train)\n",
    "transformed_test = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In addition to imputing missing values, we also want to scale the numeric columns. We can do this using StandardScaler, but not until the missing values have been imputed (it will throw an error). \n",
    "\n",
    "So it makes sense that imputation and scaling are preprocessing steps that happen in sequence. This is what sklearn's Pipeline() is for. Since each processing step (or BaseEstimator, in sklearn nomenclature) has a .fit() and .transform() method, they can be easily linked together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Define a pipeline that first imputes missing values and then scales all the continuous variables to have mean=0 and variance=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline(\n",
    "    ### Your code goes here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_train = pipe.fit_transform(X_train)\n",
    "transformed_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features\n",
    "\n",
    "At this point, we have two 'threads' going. We have a couple of transformations that make sense for categorical variables, and a pipeline of transformations that make sense for the continuous variables. Now, let's put it all together into one big preprocessing object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Combine the categorical steps into a single pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline(\n",
    "    ### Your code goes here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_train = categorical_pipe.fit_transform(X_train)\n",
    "transformed_test = categorical_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use sklearn's FeatureUnion to combine both of your pipelines (one continuous and one categorical) into a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "fu = FeatureUnion( \n",
    "    ### Your code goes here  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_train = fu.fit_transform(X_train)\n",
    "transformed_test = fu.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The great thing about this paradigm is that you can write a whole data processing a modeling pipeline 'in the abstract' without doing anthing to your data. Scikit-learn then lets you treat the entire pipeline as one 'model', which allows you to do things like cross-validation and model selection without ever contaminating your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocess', FeatureUnion([\n",
    "        ('numeric', Pipeline([\n",
    "            ('impute', MyImputer(cols=numeric_predictors)),\n",
    "            ('scale', StandardScaler()),\n",
    "            ('reduce_dim', PCA())\n",
    "        ])\n",
    "        ),\n",
    "        ('categorical', Pipeline([\n",
    "            ('impute', CategoricalImputer(cols=['county'])),\n",
    "            ('vectorize', MyVectorizer(cols=['county']))\n",
    "        ])\n",
    "        )\n",
    "    ])),\n",
    "    ('predict', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some hyper-parameters to search over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'preprocess__categorical__vectorize__hashing': [None, 20, 40, 80],\n",
    "    'preprocess__numeric__reduce_dim__n_components': [10, 20, 40, 80, 100]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(ridge_pipeline, search_params)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Try to build your own pipeline. You can use a different estimator (e.g. Ridge(), RandomForestRegressor(), GradientBoostingRegressor(), SVR(), ...), and you can also add additional variables to the steps in the pipeline (e.g., what happens if you impute missing values based on median instead of mean?)\n",
    "\n",
    "How high can you get your R^2 on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
