{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression\n",
    "\n",
    "- Regression is a technique for supervised learning that is based on strong statistical assumptions about the underlying data. Linear and logistic regression are just two different assumptions on the data\n",
    "- Regression can be used when the assumptions are not met, but then it needs to be graded based on _performance on the test data_. P-values, F-scores, etc.. depend on the assumptions being true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y \\in \\mathbb{R}$ be a random variable (the target) and $X = x_1, \\ldots, x_p$ be a set of _independent_ variables (the predictors). Then\n",
    "$$\n",
    "y \\sim \\cal{N}(\\mu, \\sigma)\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\mu = \\mu(X) = w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_p x_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Test Data\n",
    "\n",
    "Let's generate some sample data that matches the assumptions exactly.\n",
    "\n",
    "1. Set p = 3\n",
    "2. Choose a formula for $\\mu(X)$\n",
    "$$\n",
    "\\mu(X) = 5 - 9 x_1 + 3 x_2 + 2 x_3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is a linear function of the features, plus some gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover the formula using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y \\in \\{0, 1\\}$ be a random variable (the target) and $X = x_1, \\ldots, x_p$ be a set of _independent_ variables (the predictors). Then\n",
    "$$\n",
    "y \\sim \\cal{Ber}(p)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "p = p(X) = f(w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_p x_p)\n",
    "$$\n",
    "and $f$ is the _logistic function_\n",
    "$$\n",
    "f(t) = \\frac{1}{1 + e^{-t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Test Data\n",
    "\n",
    "Let's generate some sample data that matches the assumptions exactly.\n",
    "\n",
    "1. Set p = 3\n",
    "2. Choose a formula for $p(X)$\n",
    "$$\n",
    "p(X) = f(5 - 9 x_1 + 3 x_2 + 2 x_3)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Generate logistic regression data according to the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def make_target_logistic(row):\n",
    "    \"\"\"\n",
    "    Return either 0 or 1, according to a Bernoulli distribution defined by row.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# X['target'] = X.apply(lambda row: make_target_logistic(row), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recover coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit logistic model\n",
    "logit = LogisticRegression(C=1e18)\n",
    "logit.fit(X.iloc[:,:-1], X['target'])\n",
    "\n",
    "print 'Intercept: {:.3}'.format(logit.intercept_)\n",
    "\n",
    "print 'Coeffs: ', logit.coef_\n",
    "\n",
    "print 'Accuracy: {:.3}'.format(logit.score(X.iloc[:, :-1], X['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "        'wTx': X.apply(lambda row: np.dot(row[:3], logit.coef_.flatten()), axis=1),\n",
    "        'Predicted Probability': logit.predict_proba(X.iloc[:, :-1])[:,1],\n",
    "        'Actual': X['target']\n",
    "    })\n",
    "\n",
    "ax = results.plot(x='wTx', y='Predicted Probability', kind='scatter', \n",
    "                  label = 'Predicted', color='lightblue')\n",
    "results.plot(x='wTx', y='Actual', kind='scatter', ax=ax, label='Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any type of regression, one learns the model parameters by:\n",
    "\n",
    "1. Assume the probabilistic model is correct.\n",
    "2. Compute the _likelihood_ of each data point for a given set of parameters $w_0, \\ldots, w_p$. (just evaluate the PDF at that point and target value)\n",
    "3. Choose the set of parameters that maximizes the total likelihood. (or, equivalently, minimizes the log-likelihood)\n",
    "\n",
    "For linear regression, it turns out that ${\\cal l} (X) \\sim ||w^T x - y||^2$. So maximizing the likelihood is the same as minimizing the mean-squared error.\n",
    "\n",
    "For logistic regression,\n",
    "$$\n",
    "{\\cal l} (x) := -y \\log(f(w^T x)) - (1 - y) \\log(1 - f(w^Tx))\n",
    "$$\n",
    "\n",
    "In either case, regularization just means that instead of directly minimizing ${\\cal L}(X)$, we also add a penalty on the size of coefficients.\n",
    "\n",
    "#### L1 (Lasso) Regularization\n",
    "\n",
    "Find $w$ that minimizes \n",
    "$$\n",
    "{\\cal l}(X) + \\lambda \\sum_{i=1}^p |w_i|\n",
    "$$\n",
    "\n",
    "#### L2 (Ridge) Regularization\n",
    "\n",
    "Find $w$ that minimizes \n",
    "$$\n",
    "{\\cal l}(X) + \\lambda \\sum_{i=1}^p ||w_i||^2\n",
    "$$\n",
    "\n",
    "#### Elastic Net Regularization\n",
    "\n",
    "Find $w$ that minimizes \n",
    "$$\n",
    "{\\cal l}(X) + (1 - \\alpha) \\cdot \\lambda \\sum_{i=1}^p |w_i|^2 + \\alpha \\cdot \\lambda \\sum_{i=1}^p ||w_i||\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load some crime data\n",
    "headers = pd.read_csv('comm_names.txt', squeeze=True)\n",
    "headers = headers.apply(lambda s: s.split()[1])\n",
    "crime = (pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', \n",
    "                    header=None, na_values=['?'], names=headers)\n",
    "         .iloc[:, 5:]\n",
    "         .dropna()\n",
    "         )\n",
    "\n",
    "# Set target and predictors\n",
    "target = 'ViolentCrimesPerPop'\n",
    "predictors = [c for c in crime.columns if not c == target]\n",
    "\n",
    "# Train/test split\n",
    "train_df, test_df = train_test_split(crime, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: \n",
    "\n",
    "1. Fit a linear regression model on train_df. The goal is to predict 'ViolentCrimesPerPop' from the other columns. What is the r-squared on the train data? What about the test data?\n",
    "2. Also fit each of a ridge, lasso, and elastic net regression on the same data. Use the functions RidgeCV, LassoCV, and ElasticNetCV to cross-validate and find the best values of $\\lambda$ and $\\alpha$.\n",
    "3. Which model performs the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "1. Make the following scatterplot\n",
    "    - Each point corresponds to one predictor in the data\n",
    "    - The x-value is the coefficient of that predictor under OLS regression\n",
    "    - The y-value is the coefficient of that predictor using ridge regularization\n",
    "2. Do the same for OLS vs Lasso, and OLS vs ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: \n",
    "\n",
    "What is the story with the two 'large coefficients' found by OLS that are squashed by regularization? (You may have to do some digging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question:\n",
    "\n",
    "Can we tell from this process which predictors are _the most important_ for predicting violent crimes?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
