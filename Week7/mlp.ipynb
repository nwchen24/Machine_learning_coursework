{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Tensorflow\n",
    "\n",
    "### Goals\n",
    "- Gain a basic understanding of the what/how/why of Tensorflow\n",
    "- Implement a simple multi-layer perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow (and other 'deep learning' libraries) are really good at gradient descent. \n",
    "\n",
    "Three types of objects\n",
    "- Placeholders where we will use real data\n",
    "- Variables. These are the model parameters - they can be updated using gradient descent.\n",
    "- Constants.\n",
    "\n",
    "Use these objects to construct a loss function. Then use gradient descent to find the best parameters, given the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "Placeholders are the objects that will be filled with real data at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the linear equation\n",
    "$$\n",
    "y = 3 x - 3\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables need to be initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could define some y values and see how well it fits the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load some crime data\n",
    "headers = pd.read_csv('comm_names.txt', squeeze=True)\n",
    "headers = headers.apply(lambda s: s.split()[1])\n",
    "crime = (pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', \n",
    "                    header=None, na_values=['?'], names=headers)\n",
    "         .iloc[:, 5:]\n",
    "         .dropna()\n",
    "         )\n",
    "\n",
    "# Set target and predictors\n",
    "target = 'ViolentCrimesPerPop'\n",
    "predictors = [c for c in crime.columns if not c == target]\n",
    "\n",
    "# Train/test split\n",
    "X = crime[predictors]\n",
    "y = crime[[target]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1: Run 10000 gradient descent steps of the model above. Every 500 iterations, note the train error and the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Compare your results above to LinearRegression in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: In Week 5, we found that the best ridge regularization parameter for this data was alpha=11.8. Try to add the same amount of regularization to the tensorflow model above, then compare with ridge regression in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron (MLP)\n",
    "\n",
    "![](mlp.png)\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Build a multi-layer perceptron to predict crime rates.\n",
    "\n",
    "Start with two hidden units. You should be able to define one matrix transforms the inputs to the hidden layer, and a second matrix that will transform the hidden layer to the output.\n",
    "\n",
    "Don't forget add bias at each step and to apply a nonlinear transformation to the hidden layer (e.g. tf.nn.sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim_hidden = 2\n",
    "\n",
    "# input\n",
    "\n",
    "# output\n",
    "\n",
    "# Input to hidden\n",
    "\n",
    "\n",
    "# Hidden to output\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "\n",
    "# Loss\n",
    "\n",
    "\n",
    "# Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have something working, it is time to tune your network to find the right number of hidden layers and amount of regularization.\n",
    "\n",
    "1. Use your code block from above that performs gradient descent steps and records intermediate results.\n",
    "2. You might want to force the optimizer to be stochastic. That is, feed it 100 random training examples at each step instead of the whole training dataset.\n",
    "3. Start with two hidden units and try to get the regularization right. Then slowly increase the number of hidden units and continue tuning the regularization.\n",
    "4. If the training error is high, you have too much bias. If the training and testing errors are very different, you have too much variance. If the training or testing errors are jumping all over the place, your step size is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Add _another_ hidden layer.\n",
    "\n",
    "Can you decrease the MSE on the test set even further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim_h1 = 8\n",
    "dim_h2 = 8\n",
    "\n",
    "# input\n",
    "x = tf.placeholder(tf.float32, [None, dim_input])\n",
    "\n",
    "# target\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# Input to hidden 1\n",
    "W1 = tf.Variable(tf.random_normal([dim_input, dim_h1]))\n",
    "b1 = tf.Variable(tf.random_normal([dim_h1]))\n",
    "\n",
    "# Hidden 1 to hidden 2\n",
    "W2 = tf.Variable(tf.random_normal([dim_h1, dim_h2]))\n",
    "b2 = tf.Variable(tf.random_normal([dim_h2]))\n",
    "\n",
    "# Hidden 2 to output\n",
    "W3 = tf.Variable(tf.random_normal([dim_h2, dim_output]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# Model\n",
    "H1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "H2 = tf.nn.tanh(tf.matmul(H1, W2) + b2)\n",
    "y = tf.matmul(H2, W3) + b3\n",
    "\n",
    "# Loss\n",
    "mse = tf.reduce_mean(tf.square(y - y_))\n",
    "lam = .4\n",
    "reg = tf.reduce_mean(lam * tf.square(W1)) + \\\n",
    "    tf.reduce_mean(lam * tf.square(W2)) + \\\n",
    "    tf.reduce_mean(lam * tf.square(W3))\n",
    "loss = mse + reg\n",
    "\n",
    "# Optimizer\n",
    "train_step = tf.train.AdamOptimizer(0.0005).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    idx = np.random.choice(X_train.shape[0], 150, replace=True)\n",
    "    X_batch = X_train.iloc[idx, :]\n",
    "    y_batch = y_train.iloc[idx, :]\n",
    "    if i % 1000 == 0:\n",
    "        train_mse = sess.run(mse, {x: X_batch, y_: y_batch})\n",
    "        test_mse = sess.run(mse, {x: X_test, y_: y_test})\n",
    "        print 'Iteration: {:04} \\t Train Loss: {:.3} \\t Test Loss: {:.3}'.format(i, train_mse, test_mse)\n",
    "    batch_update(sess, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
