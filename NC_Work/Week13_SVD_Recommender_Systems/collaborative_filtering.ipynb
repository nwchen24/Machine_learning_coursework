{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Joke Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we'll use some joke rating data to check out recommendating systems, in particular collaborative filtering:\n",
    "\n",
    "Here's a link to the place where I got the data:\n",
    "http://goldberg.berkeley.edu/jester-data/\n",
    "\n",
    "Check out some jokes, and get recommended jokes based on your ratings:\n",
    "http://eigentaste.berkeley.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "- Each row is a user\n",
    "- The first column is the total number of jokes rated by that user.\n",
    "- The remaining columns are the ratings of the individual jokes, from -10 to 10\n",
    "- An entry of 99 means no rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.82,  8.79, -9.66, -8.16, -7.52],\n",
       "       [ 4.08, -0.29,  6.36,  4.37, -2.38],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  9.03],\n",
       "       [ 0.  ,  8.35,  0.  ,  0.  ,  1.8 ],\n",
       "       [ 8.5 ,  4.61, -4.17, -5.39,  1.36]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('jester_data.csv', header=None).values\n",
    "data[data==99] = 0\n",
    "number_rated = data[:, 0]\n",
    "ratings = data[:, 1:]\n",
    "ratings[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73421, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some EDA on the data\n",
    "\n",
    "How many jokes does an average person rate? What is most jokes rated? What is the fewest number of jokes rated?\n",
    "\n",
    "How many ratings on average does each joke have?\n",
    "\n",
    "What is a joke with the most ratings? Which is one with the fewest ratings?\n",
    "\n",
    "What is the average rating for all jokes? (Be sure to exclude the 0 values!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.0</td>\n",
       "      <td>-7.82</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>4.17</td>\n",
       "      <td>-8.98</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.37</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>7.86</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-4.32</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>8.16</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>6.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.58</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9    ...    91   \\\n",
       "0   74.0 -7.82  8.79 -9.66 -8.16 -7.52 -8.50 -9.85  4.17 -8.98  ...   2.82   \n",
       "1  100.0  4.08 -0.29  6.36  4.37 -2.38 -9.66 -0.73 -5.34  8.88  ...   2.82   \n",
       "2   49.0  0.00  0.00  0.00  0.00  9.03  9.27  9.03  9.27  0.00  ...   0.00   \n",
       "3   48.0  0.00  8.35  0.00  0.00  1.80  8.16 -2.82  6.21  0.00  ...   0.00   \n",
       "4   91.0  8.50  4.61 -4.17 -5.39  1.36  1.60  7.04  4.61 -0.44  ...   5.19   \n",
       "\n",
       "    92    93    94    95    96    97    98    99    100  \n",
       "0  0.00  0.00  0.00  0.00  0.00 -5.63  0.00  0.00  0.00  \n",
       "1 -4.95 -0.29  7.86 -0.19 -2.14  3.06  0.34 -4.32  1.07  \n",
       "2  0.00  0.00  9.08  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "3  0.00  0.00  0.53  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "4  5.58  4.27  5.19  5.73  1.55  3.11  6.55  1.80  1.60  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_DF = pd.DataFrame(data)\n",
    "ratings_DF = pd.DataFrame(ratings)\n",
    "\n",
    "data_DF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "      <td>73421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.117773</td>\n",
       "      <td>0.393423</td>\n",
       "      <td>0.078312</td>\n",
       "      <td>0.085356</td>\n",
       "      <td>-0.587042</td>\n",
       "      <td>0.235301</td>\n",
       "      <td>0.717474</td>\n",
       "      <td>-0.633774</td>\n",
       "      <td>-0.996131</td>\n",
       "      <td>-0.259607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543751</td>\n",
       "      <td>0.324124</td>\n",
       "      <td>0.659236</td>\n",
       "      <td>0.321433</td>\n",
       "      <td>0.309997</td>\n",
       "      <td>0.414464</td>\n",
       "      <td>0.457475</td>\n",
       "      <td>0.269036</td>\n",
       "      <td>-0.011429</td>\n",
       "      <td>0.296525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.066602</td>\n",
       "      <td>3.491382</td>\n",
       "      <td>3.901926</td>\n",
       "      <td>3.621108</td>\n",
       "      <td>3.471794</td>\n",
       "      <td>5.302325</td>\n",
       "      <td>3.714736</td>\n",
       "      <td>5.610147</td>\n",
       "      <td>4.967938</td>\n",
       "      <td>3.379664</td>\n",
       "      <td>...</td>\n",
       "      <td>2.888323</td>\n",
       "      <td>2.820525</td>\n",
       "      <td>2.760490</td>\n",
       "      <td>2.870173</td>\n",
       "      <td>2.885717</td>\n",
       "      <td>2.762403</td>\n",
       "      <td>2.904044</td>\n",
       "      <td>3.008637</td>\n",
       "      <td>2.940424</td>\n",
       "      <td>2.789072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "      <td>-9.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.870000</td>\n",
       "      <td>-5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.290000</td>\n",
       "      <td>-0.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>9.660000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.560000</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.420000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>9.810000</td>\n",
       "      <td>9.370000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  73421.000000  73421.000000  73421.000000  73421.000000  73421.000000   \n",
       "mean      56.117773      0.393423      0.078312      0.085356     -0.587042   \n",
       "std       29.066602      3.491382      3.901926      3.621108      3.471794   \n",
       "min        0.000000     -9.950000     -9.950000     -9.950000     -9.950000   \n",
       "25%       29.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%       52.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       75.000000      0.530000      0.390000      0.000000      0.000000   \n",
       "max      100.000000      9.610000      9.370000      9.610000      9.370000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  73421.000000  73421.000000  73421.000000  73421.000000  73421.000000   \n",
       "mean       0.235301      0.717474     -0.633774     -0.996131     -0.259607   \n",
       "std        5.302325      3.714736      5.610147      4.967938      3.379664   \n",
       "min       -9.950000     -9.950000     -9.950000     -9.950000     -9.950000   \n",
       "25%       -4.030000      0.000000     -5.870000     -5.190000      0.000000   \n",
       "50%        0.920000      0.000000     -0.290000     -0.630000      0.000000   \n",
       "75%        4.370000      2.380000      3.880000      2.770000      0.000000   \n",
       "max        9.510000      9.660000     10.000000      9.760000      9.900000   \n",
       "\n",
       "           ...                91            92            93            94   \\\n",
       "count      ...       73421.000000  73421.000000  73421.000000  73421.000000   \n",
       "mean       ...           0.543751      0.324124      0.659236      0.321433   \n",
       "std        ...           2.888323      2.820525      2.760490      2.870173   \n",
       "min        ...          -9.950000     -9.950000     -9.950000     -9.950000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           9.560000      9.610000      9.370000      9.420000   \n",
       "\n",
       "                95            96            97            98            99   \\\n",
       "count  73421.000000  73421.000000  73421.000000  73421.000000  73421.000000   \n",
       "mean       0.309997      0.414464      0.457475      0.269036     -0.011429   \n",
       "std        2.885717      2.762403      2.904044      3.008637      2.940424   \n",
       "min       -9.950000     -9.950000     -9.950000     -9.950000     -9.950000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.370000      9.370000      9.370000      9.370000      9.810000   \n",
       "\n",
       "                100  \n",
       "count  73421.000000  \n",
       "mean       0.296525  \n",
       "std        2.789072  \n",
       "min       -9.950000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        9.370000  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_DF.describe()\n",
    "\n",
    "#average of 56 ratings per user\n",
    "#most jokes rated is all 100 jokes\n",
    "#fewest number of jokes rated is zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "41237.56\n"
     ]
    }
   ],
   "source": [
    "#number of people who rated each joke\n",
    "ratings_per_joke = ratings_DF.astype(bool).sum(axis=0)\n",
    "\n",
    "#most ratings is joke number 15\n",
    "print np.argmax(ratings_per_joke)\n",
    "\n",
    "\n",
    "print np.mean(ratings_per_joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31926\n",
       "1    35178\n",
       "2    32296\n",
       "3    30430\n",
       "4    73194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_per_joke.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unregularized SVD Based Collaborative Filtering\n",
    "\n",
    "## step 1: full SVD\n",
    "\n",
    "We'll do a simple though not very effective way at collaborative filtering: a simple SVD approach.\n",
    "\n",
    "SVD (singular value decomposition) is a way of decomposing a matrix into thing like eigenvectors and eigenvalues. It looks like this for a matrix M:\n",
    "\n",
    "M = U * S * V\n",
    "\n",
    "Here, if we suppose M is an n by p matrix:\n",
    "U is an N by p matrix\n",
    "S is a p by p diagonal matrix\n",
    "V is a p by p matrix\n",
    "\n",
    "In our problem, we have n users rating p jokes\n",
    "\n",
    "In recommender problems, it has the interpretation as follows:\n",
    "U is a representation of the users, as p features\n",
    "V is a representation of the jokes, as p features (different from those in U)\n",
    "S is a vector that gives the joint importance of both feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73421, 100)\n",
      "(100,)\n",
      "(100, 100)\n",
      "[[-7.82  8.79 -9.66 ...,  0.    0.    0.  ]\n",
      " [ 4.08 -0.29  6.36 ...,  0.34 -4.32  1.07]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " ..., \n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]]\n",
      "[[ -7.82000000e+00   8.79000000e+00  -9.66000000e+00 ...,  -2.57571742e-14\n",
      "   -4.06341627e-14  -5.32907052e-14]\n",
      " [  4.08000000e+00  -2.90000000e-01   6.36000000e+00 ...,   3.40000000e-01\n",
      "   -4.32000000e+00   1.07000000e+00]\n",
      " [  1.18133678e-14   2.25933694e-14   2.08051887e-14 ...,   2.39808173e-14\n",
      "    1.31006317e-14  -1.99840144e-15]\n",
      " ..., \n",
      " [  9.53566584e-15   1.53360951e-15   2.01976018e-15 ...,   2.44249065e-15\n",
      "   -1.77635684e-15   1.99840144e-15]\n",
      " [  1.05011316e-14   1.25922002e-14   1.79581777e-14 ...,   2.66453526e-15\n",
      "    3.83026943e-15   8.88178420e-16]\n",
      " [  1.21649734e-14  -5.40528933e-15  -3.22277500e-15 ...,  -6.80011603e-15\n",
      "   -2.22044605e-16  -2.88657986e-15]]\n"
     ]
    }
   ],
   "source": [
    "# full svd; note the first column is dropped since that has the number of jokes rated, we don't care about that\n",
    "u, s, v = np.linalg.svd(ratings, full_matrices=False)\n",
    "\n",
    "print u.shape\n",
    "print s.shape\n",
    "print v.shape\n",
    "\n",
    "# these are (nearly) the same, that's the decomposition!\n",
    "print data[:, 1:]\n",
    "print np.dot(np.dot(u, np.diag(s)), v) # the full reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: Filling in values by truncating the SVD\n",
    "\n",
    "The SVD above just recovers the original matrix. That is not very interesting, we want to get a new estimate for those missing values. To do this, we need to drop dimensions.\n",
    "\n",
    "Inspect S, you should see that it is sorted in decreasing order. Write code to only take the first few dimensions in each of the projections. This means simply to replace the matrix S (you will have to construct it using np.diag) with a new matrix with many of the diagonal values zeroed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_adj = s.copy()\n",
    "\n",
    "#create new S where we set the values of everything other than the first three values equal to zero\n",
    "#This makes everything after the first three latent features have zero weight when we reconstruct the ratings.\n",
    "s_adj[3:] = 0\n",
    "\n",
    "s_adj_diag = np.diag(s_adj)\n",
    "s_adj_diag\n",
    "\n",
    "#reconstruct \n",
    "ratings_pred = np.dot(np.dot(u, s_adj_diag), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have an approximation to the original matrix. Take the filled in values only and compare them to the non filled in values, do this for a few users and jokes. You might find it useful to write a function to inspect a row or column. Considering doing things like:\n",
    "\n",
    "0. Count how many values are filled in, how many were already present for that row / column\n",
    "1. Compare the range of the filled in values with those not filled in within the row or column\n",
    "2. Compare the mean of the filled in values with those not filled in within the row or column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = ratings_DF.iloc[4,]\n",
    "#test.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 25 was actually rated by 48443 users\n",
      "Predictions for joke 25 were filled in for 48443 users\n",
      "The mean of non-zero actual ratings for joke 25 is 4.22328358209\n",
      "The mean of non-zero predicted ratings for joke 25 is 3.12938155219\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert predicted values to dataframe\n",
    "ratings_pred_DF = pd.DataFrame(ratings_pred)\n",
    "\n",
    "\n",
    "def inspect_filled_in_joke(ii):\n",
    "    #how many values were filled in in the actual ratings?\n",
    "    filled_in_actual = ratings_DF.astype(bool).sum(axis=0)\n",
    "    filled_in_actual_joke = filled_in_actual[ii]\n",
    "    print \"Joke \" + str(ii) + \" was actually rated by \" + str(int(filled_in_actual_joke)) + \" users\"\n",
    "    \n",
    "    #how many values were filled in in the predicted ratings\n",
    "    filled_in_pred = ratings_pred_DF.astype(bool).sum(axis=1)\n",
    "    filled_in_pred_joke = filled_in_actual[ii]\n",
    "    print \"Predictions for joke \" + str(ii) + \" were filled in for \" + str(int(filled_in_pred_joke)) + \" users\"\n",
    "    \n",
    "    #look at the mean of filled in actual ratings and filled in predicted ratings\n",
    "    filled_in_actual = ratings_DF.iloc[ii,]\n",
    "    #get non-zero ratings\n",
    "    filled_in_actual_non_zero = filled_in_actual[filled_in_actual.astype(bool)]\n",
    "    #get mean\n",
    "    mean_actual = np.mean(filled_in_actual_non_zero)\n",
    "    print \"The mean of non-zero actual ratings for joke \" + str(ii) + \" is \" + str(mean_actual)\n",
    "    \n",
    "    filled_in_pred = ratings_pred_DF.iloc[ii,]\n",
    "    #get non-zero ratings\n",
    "    filled_in_pred_non_zero = filled_in_pred[filled_in_pred.astype(bool)]\n",
    "    #get mean\n",
    "    mean_pred = np.mean(filled_in_pred_non_zero)\n",
    "    print \"The mean of non-zero predicted ratings for joke \" + str(ii) + \" is \" + str(mean_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "def inspect_filled_in_user(ii):\n",
    "    pass\n",
    "\n",
    "inspect_filled_in_joke(25)\n",
    "print \"\\n-----\\n\"\n",
    "inspect_filled_in_user(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Let's actually use this thing. \n",
    "\n",
    "Write a function to recommend a joke (s)he's not rated to a user who has at least one unrated joke. Use it for a few people and print the results.\n",
    "\n",
    "Use it on all users and make a histogram of the recommendations. Compare this to a histogram of missing values (number of times a joke was not rated). Does this system recommend a joke very often? Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Examining the joke and user spaces\n",
    "\n",
    "The SVD gave us projections of both the users and the jokes. Let's see if those projections give us any insight.\n",
    "\n",
    "Now, plot the first two rows (the projection dimensions appear on the rows here) of the joke projection matrix. Are there different types of jokes?\n",
    "\n",
    "Plot the first two columns (the projection dimensions appear on the columns here) of the user projection matrix. Are there different types of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73421, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x104b00cd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAFkCAYAAAAQQyCBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132299410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(u[0,], u[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Machine_learning_python2]",
   "language": "python",
   "name": "conda-env-Machine_learning_python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
